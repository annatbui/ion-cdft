{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cdf7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import minimise\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Enable or disable Tensor Float 32 Execution\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "params = {\"axes.labelsize\": 14,\n",
    "          \"axes.titlesize\": 16,}\n",
    "plt.rcParams[\"axes.linewidth\"] = 1\n",
    "plt.rcParams['mathtext.bf'] = 'STIXGeneral:italic:bold'\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "def place(ax):\n",
    "  ax.tick_params(direction=\"in\", which=\"minor\", length=3)\n",
    "  ax.tick_params(direction=\"in\", which=\"major\", length=5, labelsize=13)\n",
    "  ax.grid(which=\"major\", ls=\"dashed\", dashes=(1, 3), lw=0.8, zorder=0)\n",
    "  #ax.legend(frameon=True, loc=\"best\", fontsize=12,edgecolor=\"black\")\n",
    "  fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6c21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_windows(array, bins):\n",
    "    \"\"\"\n",
    "    Generate sliding windows for the input array with a given bin size.\n",
    "\n",
    "    Parameters:\n",
    "    - array (np.ndarray): Input array.\n",
    "    - bins (int): Number of bins on each side of the central bin.\n",
    "    - mode (str): Padding mode for np.pad (default is \"wrap\").\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Array of sliding windows.\n",
    "    \"\"\"\n",
    "    padded_array = np.pad(array, bins, mode=\"wrap\")\n",
    "    windows = np.empty((len(array), 2 * bins + 1))\n",
    "    for i in range(len(array)):\n",
    "        windows[i] = padded_array[i:i + 2 * bins + 1]\n",
    "    return windows\n",
    "\n",
    "\n",
    "def c1_twotype(model_H, model_O, rho_H, rho_O, input_bins=667, dx=0.03, return_c2=False):\n",
    "    \"\"\"\n",
    "    Infer the one-body direct correlation profile from a given density profile \n",
    "    using a neural correlation functional.\n",
    "\n",
    "    Parameters:\n",
    "    - model (tf.keras.Model): The neural correlation functional.\n",
    "    - density_profile (np.ndarray): The density profile.\n",
    "    - dx (float): The discretization of the input layer of the model.\n",
    "    - input_bins (int): Number of input bins for the model.\n",
    "    - return_c2 (bool or str): If False, only return c1(x). If True, return both \n",
    "                               c1 as well as the corresponding two-body direct \n",
    "                               correlation function c2(x, x') which is obtained \n",
    "                               via autodifferentiation. If 'unstacked', give c2 \n",
    "                               as a function of x and x-x', i.e., as obtained \n",
    "                               naturally from the model.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: c1(x) or (c1(x), c2(x, x')) depending on the value of return_c2.\n",
    "    \"\"\"\n",
    "    window_bins = (input_bins - 1) // 2\n",
    "    rhoH_windows = generate_windows(rho_H, window_bins).reshape(rho_H.shape[0], input_bins, 1)\n",
    "    rhoO_windows = generate_windows(rho_O, window_bins).reshape(rho_O.shape[0], input_bins, 1)\n",
    "    \n",
    "    if return_c2:\n",
    "        rhoH_windows = tf.Variable(rhoH_windows)\n",
    "        rhoO_windows = tf.Variable(rhoO_windows)\n",
    "        with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n",
    "            tape.watch(rhoO_windows)\n",
    "            tape.watch(rhoH_windows)\n",
    "            H_result = model_H(rhoH_windows, rhoO_windows)\n",
    "            O_result = model_O(rhoH_windows, rhoO_windows)\n",
    "        jacobi_windows_HH = tape.batch_jacobian(H_result, rhoH_windows).numpy().squeeze() / dx\n",
    "        jacobi_windows_HO = tape.batch_jacobian(H_result, rhoO_windows).numpy().squeeze() / dx\n",
    "        jacobi_windows_OO = tape.batch_jacobian(O_result, rhoO_windows).numpy().squeeze() / dx\n",
    "        jacobi_windows_OH = tape.batch_jacobian(O_result, rhoH_windows).numpy().squeeze() / dx\n",
    "       \n",
    "        c1H_result = H_result.numpy().flatten()\n",
    "        c1O_result = O_result.numpy().flatten()\n",
    "        \n",
    "        if return_c2 == \"unstacked\":\n",
    "            return c1H_result, c1O_result, jacobi_windows_HH, jacobi_windows_HO, jacobi_windows_OO, jacobi_windows_OH\n",
    "        \n",
    "        c2_result_HH = np.row_stack([\n",
    "            np.roll(np.pad(jacobi_windows_HH[i], (0, rho_H.shape[0] - input_bins)), i - window_bins) \n",
    "            for i in range(rho_H.shape[0])\n",
    "        ])\n",
    "        c2_result_HO = np.row_stack([\n",
    "            np.roll(np.pad(jacobi_windows_HO[i], (0, rho_H.shape[0] - input_bins)), i - window_bins) \n",
    "            for i in range(rho_H.shape[0])\n",
    "        ])\n",
    "        c2_result_OO = np.row_stack([\n",
    "            np.roll(np.pad(jacobi_windows_OO[i], (0, rho_H.shape[0] - input_bins)), i - window_bins) \n",
    "            for i in range(rho_H.shape[0])\n",
    "        ])\n",
    "        c2_result_OH = np.row_stack([\n",
    "            np.roll(np.pad(jacobi_windows_OH[i], (0, rho_H.shape[0] - input_bins)), i - window_bins) \n",
    "            for i in range(rho_H.shape[0])\n",
    "        ])\n",
    "        \n",
    "        return (c1H_result, c2_result_HH, c2_result_HO), (c1O_result, c2_result_OO, c2_result_OH)\n",
    "\n",
    "\n",
    "   # if output_dict:\n",
    "   #     c1H_result = model_H.predict_on_batch([rhoH_windows, rhoO_windows])[\"c1_H\"].flatten()\n",
    "   #     c1O_result = model_O.predict_on_batch([rhoO_windows, rhoH_windows])[\"c1_O\"].flatten()\n",
    "   # else:\n",
    "   #     c1H_result = model_H.predict_on_batch([rhoH_windows, rhoO_windows]).flatten()\n",
    "#        c1O_result = model_O.predict_on_batch([rhoO_windows, rhoH_windows]).flatten()\n",
    "\n",
    "    c1H_result = model_H.predict_on_batch([rhoH_windows, rhoO_windows]).flatten()\n",
    "    c1O_result = model_O.predict_on_batch([rhoO_windows, rhoH_windows]).flatten()\n",
    "    return c1H_result, c1O_result\n",
    "\n",
    "\n",
    "def betaFexc_twotype(model_H, model_O, rho_H, rho_O, dx=0.03):\n",
    "    \"\"\"\n",
    "    Calculate the excess free energy Fexc for a given density profile with functional line integration.\n",
    "\n",
    "    model: The neural correlation functional\n",
    "    rho: The density profile\n",
    "    dx: The discretization of the input layer of the model\n",
    "    \"\"\"\n",
    "    alphas = np.linspace(0, 1, 30)\n",
    "    integrands = np.empty_like(alphas)\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        \n",
    "        c1H, c1O = c1_twotype(model_H, model_O, alpha * rho_H, alpha * rho_O)\n",
    "        \n",
    "        integrands[i] = np.sum(rho_H * c1H + rho_O * c1O) * dx\n",
    "    Fexc = -simpson(integrands, x=alphas)\n",
    "    return Fexc\n",
    "\n",
    "\n",
    "def Fexc(model, rho, dx=0.03):\n",
    "    \"\"\"\n",
    "    Calculate the excess free energy Fexc for a given density profile with functional line integration.\n",
    "\n",
    "    model: The neural correlation functional\n",
    "    rho: The density profile\n",
    "    dx: The discretization of the input layer of the model\n",
    "    \"\"\"\n",
    "    alphas = np.linspace(0, 1, 50)\n",
    "    integrands = np.empty_like(alphas)\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        integrands[i] = np.sum(rho * c1(model, alpha * rho)) * dx\n",
    "    Fexc = -simpson(integrands, x=alphas)\n",
    "    return Fexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65d20d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kB  = 1.38064852e-23\n",
    "T = 4000\n",
    "\n",
    "model_H_path = \"../../models/RPM_all_H.keras\"\n",
    "model_O_path = \"../../models/RPM_all_O.keras\"\n",
    "modelH_path = \"../../models/RPM_H_Aug22.keras\"\n",
    "modelO_path = \"../../models/RPM_O_Aug22.keras\"\n",
    "modelH_path = \"../../models/RPM_H_PC_Aug24.keras\"\n",
    "modelO_path = \"../../models/RPM_O_PC_Aug24.keras\"\n",
    "\n",
    "model_H = keras.models.load_model(model_H_path)\n",
    "model_O = keras.models.load_model(model_O_path)\n",
    "\n",
    "\n",
    "rho_range = np.linspace(0.0, 0.02, 50)\n",
    "Fexc_range = np.empty_like(rho_range)\n",
    "derivPhiH = np.empty_like(rho_range)\n",
    "derivPhiO = np.empty_like(rho_range)\n",
    "z_range = np.ones(1)\n",
    "\n",
    "\n",
    "for i in range(len(rho_range)):\n",
    "    \n",
    "    rhoH_array = z_range * rho_range[i]\n",
    "    rhoO_array = z_range * rho_range[i]\n",
    "    \n",
    "    Fexc_range[i] = kB * T * betaFexc_twotype(model_H, model_O, rhoH_array, rhoO_array, dx=0.03)\n",
    "    c1H, c1O, = c1_twotype(model_H, model_O, rhoH_array, rhoO_array)\n",
    "    derivPhiH[i] = -np.mean(c1H) * kB * T\n",
    "    derivPhiO[i] = -np.mean(c1O) * kB * T\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1228736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_range = (derivPhiH + kB*T) * rho_range + (derivPhiO + kB*T) * rho_range - Fexc_range/0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3733e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/scratch/btb32/gcmc-training/rpm/SR-pair-correlation/pressure_sr.txt\"\n",
    "data = pd.read_csv(path, skiprows=1, header=None, sep=r'\\s+').to_numpy()\n",
    "\n",
    "rho_sim = data[:,0]/2\n",
    "P_sim = data[:,1]\n",
    "P_err_sim = data[:,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346239c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "angtrom3_to_m3 = 1e30\n",
    "pa_to_atm = 101325\n",
    "\n",
    "P_range_atm = P_range * angtrom3_to_m3/pa_to_atm\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4,3))\n",
    "\n",
    "ax.plot(rho_range, P_range_atm, lw=1, color=\"crimson\")\n",
    "#ax.plot(rho_sim, P_sim, lw=2, color=\"blue\", ls=\"--\")\n",
    "ax.fill_between(rho_sim, P_sim-P_err_sim, P_sim+P_err_sim, color=\"hotpink\", alpha=0.3)\n",
    "ax.set_xlabel(r\"$\\rho$\")\n",
    "ax.set_ylabel(r\"$P$ [atm]\")\n",
    "place(ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6393dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/scratch/btb32/cdft-ions-paper/data/pressure_sr.dat', 'w', newline='') as csvfile:\n",
    "#        writer = csv.writer(csvfile, delimiter=' ')\n",
    "#        writer.writerow([\"rhoH=rhoO [per AA cubed]\", \"pressure [atm]\"])\n",
    "#        for x, y in zip(rho_range, P_range_atm):\n",
    "#            writer.writerow([f\"{x:.10f}\", f\"{y:.10f}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_pressure_correction(sigma, T):\n",
    "    kB = 1.38064852e-23\n",
    "    return - kB*T/(2 * np.pi**1.5 * sigma**3)\n",
    "\n",
    "print(LR_pressure_correction(3, 4000)*angtrom3_to_m3/pa_to_atm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
