{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "params = {\"axes.labelsize\": 14,\n",
    "          \"axes.titlesize\": 16,}\n",
    "plt.rcParams[\"axes.linewidth\"] = 1\n",
    "plt.rcParams['mathtext.bf'] = 'STIXGeneral:italic:bold'\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "def place(ax):\n",
    "  ax.tick_params(direction=\"in\", which=\"minor\", length=3)\n",
    "  ax.tick_params(direction=\"in\", which=\"major\", length=5, labelsize=13)\n",
    "  ax.grid(which=\"major\", ls=\"dashed\", dashes=(1, 3), lw=0.8, zorder=0)\n",
    "  #ax.legend(frameon=True, loc=\"best\", fontsize=12,edgecolor=\"black\")\n",
    "  fig.tight_layout()\n",
    "\n",
    "\n",
    "def combine_data(xbins, rho_O, rho_H, mu_O, mu_H,\n",
    "                 muloc_O, muloc_H, c1_O, c1_H):\n",
    "    data = {}\n",
    "    \n",
    "    data = np.zeros(xbins.shape, dtype=[('xbins', 'f8'),\n",
    "                                        ('rho_O', 'f8'), ('muloc_O', 'f8'), ('c1_O', 'f8'), ('mu_O', 'f8'),\n",
    "                                        ('rho_H', 'f8'), ('muloc_H', 'f8'), ('c1_H', 'f8'), ('mu_H', 'f8'),\n",
    "                                        ('elec_O', 'f8'), ('elec_H', 'f8')])\n",
    "    \n",
    "    data['xbins'] = xbins\n",
    "    data['rho_O'] = rho_O\n",
    "    data['rho_H'] = rho_H\n",
    "    data['mu_O'] = mu_O\n",
    "    data['mu_H'] = mu_H\n",
    "    data['muloc_O'] = muloc_O\n",
    "    data['muloc_H'] = muloc_H\n",
    "    data['c1_O'] = c1_O\n",
    "    data['c1_H'] = c1_H\n",
    "    #data['elec_O'] = elec_O\n",
    "    #data['elec_H'] = elec_H\n",
    "    return data\n",
    "\n",
    "# Load the simData dictionary from the file\n",
    "simData_Efield = np.load(\"../../data/edl_SR.npy\", allow_pickle=True).item()\n",
    "simData_all = np.load(\"../../data/RPM_all_Aug20.npy\", allow_pickle=True).item()\n",
    "simData = {}\n",
    "\n",
    "for key in ['training', 'validation', 'test']:\n",
    "    # Combine the inner dictionaries\n",
    "    simData[key] = { **simData_all.get(key, {}), **simData_Efield.get(key, {}) }\n",
    "\n",
    "all_simulations = []\n",
    "for category in ['training', 'validation', 'test']:\n",
    "    all_simulations.extend(list(simData[category].keys()))\n",
    "    \n",
    "    \n",
    "\n",
    "for sim in all_simulations:\n",
    "    category = next(cat for cat in simData if sim in simData[cat])\n",
    "    data = simData[category][sim]\n",
    "    xbins = data['xbins']\n",
    "    rho_O = data['rho_O']\n",
    "    muloc_O = data['muloc_O']\n",
    "    c1_O = data['c1_O']\n",
    "    rho_H = data['rho_H']\n",
    "    muloc_H = data['muloc_H']\n",
    "    c1_H = data['c1_H']\n",
    "    mu_H = data['mu_H']\n",
    "    mu_O = data['mu_O']\n",
    "    #elec_H = data['elec_H']\n",
    "    #elec_O = data['elec_O']\n",
    "    \n",
    "    sim_name = sim + \"_mirror\"\n",
    "    combined_data_mirror = combine_data(xbins, rho_H, rho_O, mu_H, mu_O,\n",
    "                                    muloc_H, muloc_O, c1_H, c1_O,)\n",
    "    \n",
    "    simData[category][sim_name] = combined_data_mirror\n",
    "    \n",
    "    \n",
    "\n",
    "# Load the simData dictionary from the file\n",
    "#simData = np.load(\"../../data/RPM_all.npy\", allow_pickle=True).item()\n",
    "simPCData = np.load(\"../../data/RPM_PC.npy\", allow_pickle=True).item()\n",
    "\n",
    "\n",
    "# Combine all simulations into one list\n",
    "all_simulations = []\n",
    "for category in ['training', 'validation', 'test']:\n",
    "    all_simulations.extend(list(simData[category].keys()))\n",
    "\n",
    "PC_simulations = []\n",
    "PC_simulations.extend(list(simPCData['training'].keys()))\n",
    "\n",
    "print(len(all_simulations))\n",
    "print(len(PC_simulations))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37063c95",
   "metadata": {},
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aeb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random simulation\n",
    "random_sim = random.choice(all_simulations)\n",
    "\n",
    "# Determine which category the random simulation belongs to\n",
    "category = next(cat for cat in simData if random_sim in simData[cat])\n",
    "\n",
    "\n",
    "# Get the data for the random simulation\n",
    "data = simData[category][random_sim]\n",
    "\n",
    "# Extract z, rho, muloc, and c1\n",
    "xbins = data['xbins']\n",
    "\n",
    "rho_O = data['rho_O']\n",
    "muloc_O = data['muloc_O']\n",
    "c1_O = data['c1_O']\n",
    "rho_H = data['rho_H']\n",
    "muloc_H = data['muloc_H']\n",
    "c1_H = data['c1_H']\n",
    "elec_H = data['elec_H']\n",
    "elec_O = data['elec_O']\n",
    "\n",
    "# Plot muloc(z), rho(z), and c1(z)\n",
    "fig, ax = plt.subplots(3, 1, figsize=(5,6), sharex='all')\n",
    "\n",
    "\n",
    "ax[0].plot(xbins, muloc_O, label='O', color='deepskyblue')\n",
    "ax[0].plot(xbins, muloc_H, label='H', color='hotpink')\n",
    "\n",
    "ax[0].plot(xbins, elec_O, label='O', color='deepskyblue', linestyle='--')\n",
    "ax[0].plot(xbins, elec_H, label='H', color='hotpink', linestyle='--')\n",
    "ax[0].set_ylabel(r'$\\beta\\mu - \\beta V_{\\mathrm{ext}}(x)$')\n",
    "ax[0].set_title(f'{random_sim}')\n",
    "\n",
    "ax[1].plot(xbins, rho_O, label='O', color='deepskyblue')\n",
    "ax[1].plot(xbins, rho_H, label='H', color='hotpink')\n",
    "ax[1].set_ylabel(r'$\\rho(x)$')\n",
    "\n",
    "\n",
    "ax[2].plot(xbins, c1_O, label='O', color='deepskyblue')\n",
    "ax[2].plot(xbins, c1_H, label='H', color='hotpink')\n",
    "ax[2].set_ylabel(r'$c^{(1)}(x)$')\n",
    "ax[2].set_xlabel(r'$x$ [$\\mathrm{\\AA}$]')\n",
    "ax[0].legend(frameon=True, loc=\"best\", fontsize=12,edgecolor=\"black\")\n",
    "#ax[2].set_xlim(0, 20)\n",
    "\n",
    "place(ax[1])\n",
    "place(ax[0])\n",
    "place(ax[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select a random simulation\n",
    "random_sim = random.choice(PC_simulations)\n",
    "\n",
    "# Determine which category the random simulation belongs to\n",
    "category = next(cat for cat in simPCData if random_sim in simPCData[cat])\n",
    "\n",
    "\n",
    "# Get the data for the random simulation\n",
    "data = simPCData[category][random_sim]\n",
    "\n",
    "\n",
    "xs = data['xs']\n",
    "c2_OO = data['c2_OO']\n",
    "c2_OH = data['c2_OH']\n",
    "c2_HH = data['c2_HH']\n",
    "\n",
    "\n",
    "\n",
    "# Plot muloc(z), rho(z), and c1(z)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "\n",
    "ax.set_title(f'{random_sim}')\n",
    "\n",
    "ax.plot(xs, c2_OO, label='OO', lw=2, color='deepskyblue')\n",
    "ax.plot(xs, c2_OH, label='OH', lw=2, color='hotpink')\n",
    "ax.plot(xs, c2_HH, label='HH', lw=2, ls='--', color='turquoise')\n",
    "\n",
    "\n",
    "ax.set_xlim(0, 20)\n",
    "\n",
    "place(ax)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60040fd8",
   "metadata": {},
   "source": [
    "## Curate data for training, sliding window approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_generators import DataGenerator_inhom_twotype, get_dataset_c1_O_twotype, get_dataset_c2_O_twotype\n",
    "windowSigma = 10.0\n",
    "\n",
    "\n",
    "# Generator options\n",
    "generatorOptions = {\n",
    "    \"batch_size\": 128,\n",
    "    \"windowSigma\": 10.00,\n",
    "    \"inputKeys1\": [\"rho_O\"],\n",
    "    \"inputKeys2\": [\"rho_H\"],\n",
    "    \"outputKeys\": [\"c1_O\"],\n",
    "    \"binKey\": \"xbins\",\n",
    "}\n",
    "\n",
    "# Create data generators\n",
    "trainingGenerator = DataGenerator_inhom_twotype(simData[\"training\"], **generatorOptions)\n",
    "validationGenerator = DataGenerator_inhom_twotype(simData[\"validation\"], **generatorOptions)\n",
    "train_dataset_c1O = get_dataset_c1_O_twotype(trainingGenerator)\n",
    "validation_dataset_c1O = get_dataset_c1_O_twotype(validationGenerator)\n",
    "train_dataset_c2OO = get_dataset_c2_O_twotype(simPCData[\"training\"], windowSigma, trainingGenerator.input1Shape, trainingGenerator.input2Shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cde3e",
   "metadata": {},
   "source": [
    "\n",
    "## Create neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf79bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Define the model inputs\n",
    "rho_O_input = keras.Input(shape=trainingGenerator.input2Shape, name=\"rho_O\")\n",
    "rho_H_input = keras.Input(shape=trainingGenerator.input1Shape, name=\"rho_H\")\n",
    "\n",
    "# Flatten array\n",
    "x_O = keras.layers.Flatten()(rho_O_input)\n",
    "x_H = keras.layers.Flatten()(rho_H_input)\n",
    "\n",
    "\n",
    "# Concatenate the two inputs\n",
    "x = keras.layers.Concatenate()([x_O, x_H])\n",
    "x = keras.layers.Dense(512, activation=\"softplus\")(x)\n",
    "x = keras.layers.Dense(512, activation=\"softplus\")(x)\n",
    "x = keras.layers.Dense(512, activation=\"softplus\")(x)\n",
    "\n",
    "\n",
    "\n",
    "outputs = {\"c1_O\": keras.layers.Dense(trainingGenerator.outputShape[0], name=\"c1_O\")(x)}\n",
    "\n",
    "inputs = [rho_O_input, rho_H_input]\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True, show_layer_names=True ,show_layer_activations=True, dpi=80, to_file='model_RPM.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766e65e",
   "metadata": {},
   "source": [
    "Pair-correlation matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e384c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Custom training loop with optional pair-correlation matching\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Define your validation step\n",
    "@tf.function\n",
    "def validation_step(x_val, y_val):\n",
    "    val_predictions = model(x_val, training=False)[\"c1_O\"]\n",
    "    val_loss = loss(y_val[\"c1_O\"], val_predictions)\n",
    "    return val_loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_c1, y_c1, x_c2x=None, y_c2x=None, alpha_c1=1, alpha_c2x=0.001, dx=0.03):\n",
    "    with tf.GradientTape() as tape:\n",
    "        c1_model = model(x_c1, training=True)[\"c1_O\"]\n",
    "        loss_c1 = loss(y_c1[\"c1_O\"], c1_model)\n",
    "        loss_c2x = 0\n",
    "        if alpha_c2x > 0:\n",
    "            with tf.GradientTape(watch_accessed_variables=False) as tape2:\n",
    "                tape2.watch(x_c2x)\n",
    "                c1_model_pc = model(x_c2x, training=True)[\"c1_O\"]\n",
    "            c2OO_model = tape2.gradient(c1_model_pc, x_c2x[\"rho_O\"]) / dx\n",
    "            loss_c2OOx = loss(y_c2x[\"c2_OO\"], c2OO_model) \n",
    "            \n",
    "            with tf.GradientTape(watch_accessed_variables=False) as tape3:\n",
    "                tape3.watch(x_c2x)\n",
    "                c1_model_pc = model(x_c2x, training=True)[\"c1_O\"]\n",
    "            c2OH_model = tape3.gradient(c1_model_pc, x_c2x[\"rho_H\"]) / dx\n",
    "            loss_c2OHx = loss(y_c2x[\"c2_OH\"], c2OH_model)\n",
    "            \n",
    "            loss_c2x = loss_c2OOx + loss_c2OHx\n",
    "            \n",
    "        loss_total = alpha_c1 * loss_c1 + alpha_c2x * loss_c2x\n",
    "    grads = tape.gradient(loss_total, model.trainable_weights)\n",
    "    optimizer.apply(grads, model.trainable_weights)\n",
    "    for metric in metrics:\n",
    "        metric.update_state(y_c1[\"c1_O\"], c1_model)\n",
    "    return loss_c1, loss_c2x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStoppingCallback:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.best_val_loss = np.inf\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, val_loss):\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4e774",
   "metadata": {},
   "source": [
    "## Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e1f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStoppingCallback(patience=200)\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(166):\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(f\"\\tlearning rate: {optimizer.learning_rate.numpy():.4g}\")\n",
    "\n",
    "    for step, ((x_c1, y_c1), (x_c2x, y_c2x)) in enumerate(zip(train_dataset_c1O, train_dataset_c2OO)):\n",
    "        \n",
    "        loss_c1, loss_c2x = train_step(x_c1, y_c1, x_c2x, y_c2x, alpha_c1=1, alpha_c2x=0.0001)\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        #print(f\"\\tsteps: {step}\")\n",
    "        print(f\"\\tloss_c1: {loss_c1:.4g}\", f\"\\tloss_c2x: {loss_c2x:.4g}\")\n",
    " \n",
    "        # Validation\n",
    "        val_losses = []\n",
    "        for (x_val, y_val) in validation_dataset_c1O:\n",
    "            val_loss = validation_step(x_val, y_val)\n",
    "            val_losses.append(val_loss)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        print(f\"\\tValidation loss: {avg_val_loss:.4g}\")\n",
    "\n",
    "        # Save the best model\n",
    "        #if avg_val_loss < best_val_loss:\n",
    "        #    best_val_loss = avg_val_loss\n",
    "        #    model.save(\"../../models/RPM_PC_O.keras\")\n",
    "        #    print(f\"\\tBest model saved with validation loss: {best_val_loss:.4g}\")\n",
    "        model.save(\"../../models/RPM_O_PC_softplus.keras\")\n",
    "        #model.save(\"../../models/RPM_PC_O.keras\")\n",
    "\n",
    "        for metric in metrics:\n",
    "            print(f\"\\t{metric.name} (c1): {metric.result():.4g}\")\n",
    "            metric.reset_state()\n",
    "\n",
    "    optimizer.learning_rate *= 0.95\n",
    "    \n",
    "    if early_stopping.on_epoch_end(epoch, avg_val_loss):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6fced",
   "metadata": {},
   "source": [
    "## Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save('../../models/RPM_O_PC_Aug24.keras') \n",
    "#model = keras.models.load_model(\"../../models/RPM_O_PC_Aug24.keras\")\n",
    "\n",
    "testGenerator = DataGenerator_inhom_twotype(simData[\"test\"], **generatorOptions)\n",
    "test_metrics = model.evaluate(testGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b00b6",
   "metadata": {},
   "source": [
    "## See the predicted correlation function of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows(array, bins, mode=\"wrap\"):\n",
    "\n",
    "    padded_array = np.pad(array, bins, mode=mode)\n",
    "    windows = np.empty((len(array), 2 * bins + 1))\n",
    "    for i in range(len(array)):\n",
    "        windows[i] = padded_array[i:i + 2 * bins + 1]\n",
    "    return windows\n",
    "\n",
    "\n",
    "def c1O(model, rho_O, rho_H, input_bins=667):\n",
    "\n",
    "\n",
    "    window_bins = (input_bins - 1) // 2\n",
    "    rhoO_windows = generate_windows(rho_O, window_bins).reshape(rho_O.shape[0], input_bins, 1)\n",
    "    rhoH_windows = generate_windows(rho_H, window_bins).reshape(rho_H.shape[0], input_bins, 1)\n",
    "    \n",
    "    c1O_result = model.predict_on_batch([rhoO_windows, rhoH_windows])\n",
    "    return c1O_result[\"c1_O\"].flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine all tests simulations into one list\n",
    "all_test_simulations = []\n",
    "for category in ['test']:\n",
    "    all_test_simulations.extend(list(simData[category].keys()))\n",
    "\n",
    "\n",
    "# Select a random simulation\n",
    "random_sim = random.choice(all_test_simulations)\n",
    "#random_sim = 'sim_1077'\n",
    "# Determine which category the random simulation belongs to\n",
    "category = next(cat for cat in simData if random_sim in simData[cat])\n",
    "\n",
    "\n",
    "# Get the data for the random simulation\n",
    "data = simData[category][random_sim]\n",
    "\n",
    "# Extract z, rho, muloc, and c1\n",
    "xbins = data['xbins']\n",
    "rho_O = data['rho_O']\n",
    "muloc_O = data['muloc_O']\n",
    "c1_O = data['c1_O']\n",
    "rho_H = data['rho_H']\n",
    "muloc_H = data['muloc_H']\n",
    "c1_H = data['c1_H']\n",
    "\n",
    "# Plot muloc(z), rho(z), and c1(z)\n",
    "fig, ax = plt.subplots(3, 1, figsize=(5,6), sharex='all')\n",
    "\n",
    "\n",
    "ax[0].plot(xbins, muloc_H, label='H', color='pink')\n",
    "ax[0].plot(xbins, muloc_O, label='O', color='deepskyblue')\n",
    "\n",
    "ax[0].set_ylabel(r'$\\beta\\mu - \\beta V_{\\mathrm{ext}}(x)$')\n",
    "ax[0].set_title(f'{random_sim}')\n",
    "\n",
    "ax[1].plot(xbins, rho_H, label='H', color='pink')\n",
    "ax[1].plot(xbins, rho_O, label='O', color='deepskyblue')\n",
    "\n",
    "ax[2].plot(xbins, c1_H, label='H, sim', color='pink', lw=2)\n",
    "ax[2].plot(xbins, c1_O, label='O, sim', color='deepskyblue', lw=2)\n",
    "\n",
    "c1_O_pred = c1O(model, rho_O, rho_H)\n",
    "\n",
    "ax[2].plot(xbins, c1_O_pred, label='O, predicted', color='darkblue', ls='--')\n",
    "\n",
    "\n",
    "ax[1].set_ylabel(r'$\\rho(x)$')\n",
    "ax[2].set_ylabel(r'$c^\\mathrm{(1)}(x)$')\n",
    "\n",
    "ax[2].legend()\n",
    "ax[2].set_xlim(0, 20)\n",
    "\n",
    "place(ax[1])\n",
    "place(ax[0])\n",
    "place(ax[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407d8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
